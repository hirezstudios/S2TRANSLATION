<!-- Generated by SpecStory -->

# Untitled (2025-04-09 08:55:17)

_**User**_

For this session, please adhere very close to my exact guidance on what to do and don't do a lot of etra work on top of that. 

We are going to build a straight forward system translation app to translate items for the video game SMITE 2 using the Perplexity API, methodically step by step. 

Below is documentation on the Perplexity API. 

The .env file has a PERPLEXITY_API_KEY and a specified PERPLEXITY_MODEL

The file @blake-small.csv  is the standardized file format generated from our translation system for handling translations. It contains english strings to be translated in the column src_enUS and then it has columns for different languages. In the input file those are blank.  

The systems_prompt folder will eventually have systems prompts for all the languages we might translate, but for right now, we are just going to focus on tg_esLA (which is neutral Latin American Spanish). 

For right now, I want you to create a simple script that will use the Perplexity API to translate each string in the input csv file and create a new output csv file in the /output folder that has the tg_esLA translations in it, and the rest of the input csv preserved exactly. 

The system prompt for this should pull from the @tg_esLA.md file. 

We are going to expand on what we do after that, but I want to do just that right now and keep this simple for this first iteration. We are building brick by brick at my precise direction for now. 


  

Perplexity API
Chat Completions
Generates a model’s response for the given chat conversation.

POST
/
chat
/
completions

Try it
Authorizations
​
Authorization
stringheaderrequired
Bearer authentication header of the form Bearer <token>, where <token> is your auth token.

Body
application/json
​
model
stringrequired
The name of the model that will complete your prompt. Refer to Supported Models to find all the models offered.

Example:
"sonar"

​
messages
object[]required
A list of messages comprising the conversation so far.


Show child attributes

Example:
[
  {
    "role": "system",
    "content": "Be precise and concise."
  },
  {
    "role": "user",
    "content": "How many stars are there in our galaxy?"
  }
]
​
max_tokens
integer
The maximum number of completion tokens returned by the API. Controls the length of the model's response. If the response would exceed this limit, it will be truncated. Higher values allow for longer responses but may increase processing time and costs.

​
temperature
numberdefault:0.2
The amount of randomness in the response, valued between 0 and 2. Lower values (e.g., 0.1) make the output more focused, deterministic, and less creative. Higher values (e.g., 1.5) make the output more random and creative. Use lower values for factual/information retrieval tasks and higher values for creative applications.

Required range: 0 <= x < 2
​
top_p
numberdefault:0.9
The nucleus sampling threshold, valued between 0 and 1. Controls the diversity of generated text by considering only the tokens whose cumulative probability exceeds the top_p value. Lower values (e.g., 0.5) make the output more focused and deterministic, while higher values (e.g., 0.95) allow for more diverse outputs. Often used as an alternative to temperature.

​
search_domain_filter
any[]
A list of domains to limit search results to. Currently limited to only 3 domains for whitelisting and blacklisting. For blacklisting, add a - at the beginning of the domain string. More information about this here.

​
return_images
booleandefault:false
Determines whether search results should include images.

​
return_related_questions
booleandefault:false
Determines whether related questions should be returned.

​
search_recency_filter
string
Filters search results based on time (e.g., 'week', 'day').

​
top_k
numberdefault:0
The number of tokens to keep for top-k filtering. Limits the model to consider only the k most likely next tokens at each step. Lower values (e.g., 10) make the output more focused and deterministic, while higher values allow for more diverse outputs. A value of 0 disables this filter. Often used in conjunction with top_p to control output randomness.

​
stream
booleandefault:false
Determines whether to stream the response incrementally.

​
presence_penalty
numberdefault:0
Positive values increase the likelihood of discussing new topics. Applies a penalty to tokens that have already appeared in the text, encouraging the model to talk about new concepts. Values typically range from 0 (no penalty) to 2.0 (strong penalty). Higher values reduce repetition but may lead to more off-topic text.

​
frequency_penalty
numberdefault:1
Decreases likelihood of repetition based on prior frequency. Applies a penalty to tokens based on how frequently they've appeared in the text so far. Values typically range from 0 (no penalty) to 2.0 (strong penalty). Higher values (e.g., 1.5) reduce repetition of the same words and phrases. Useful for preventing the model from getting stuck in loops.

​
response_format
object
Enables structured JSON output formatting.

​
web_search_options
object
Configuration for using web search in model responses.


Show child attributes

Example:
{ "search_context_size": "high" }
Response
200
application/json

application/json
OK
The response is of type any. 

---

_**Assistant**_



---

Okay, I understand. We will build this translation script step-by-step, focusing only on the requested functionality for now.

First, I'll set up the basic project structure according to the custom instructions. This involves creating the `.cursor` directory with its subfolders and initial note files, creating the `output` directory, setting up a `.gitignore` file, and initializing a git repository. I'll also fetch the standard rules and tools from the specified GitHub repository.



---



---

